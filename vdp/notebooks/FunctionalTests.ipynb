{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VDP Functional Tests\n",
    "\n",
    "#### Version 1.9\n",
    "\n",
    "Last updated: 04/26/18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import vdp\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single image complete run-through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# vdp configuration file\n",
      "\n",
      "stages:\n",
      "                              # processing steps; yes | no  or  True | False\n",
      "  source finding: yes         # extract sources from image?\n",
      "  source association: yes     # match extracted sources to existing catalog?\n",
      "  catalog matching: yes       # cross-match with sky survey catalogs?\n",
      "\n",
      "options:\n",
      "                              # processing options; yes | no or True | False\n",
      "  save to database: yes       # save results to database?\n",
      "  quality checks: yes         # run image & source count quality checks?\n",
      "  overwrite: yes              # overwrite database if exists?\n",
      "  reprocess: no               # redo selected stages even if done previously?\n",
      "  redo match: no              # redo cross-matching with all sky catalogs?\n",
      "  update match: no            # update cross-matching with new sky catalogs?\n",
      "\n",
      "setup:\n",
      "  root directory: /home/erichards/work/data/test/\n",
      "  year: 2017\n",
      "  month: 08\n",
      "  day: [30]                   # list of days to process; [] = all\n",
      "  # list files to process - put different days in separate lists; [[]] = all\n",
      "  files: [[1.5GHz.0137+331.IPln1.fits]]\n",
      "  #6GHz.0137+331.IPln1.fits\n",
      "  database name: functest\n",
      "  database user: erichards\n",
      "  catalogs: []                # [] = all\n",
      "\n",
      "pybdsf_params:\n",
      "  mode: default               # default | minimize_islands\n",
      "  scale: 0.5                  # fraction (0-1) of image size (radius) to use\n",
      "  # Specify all PyBDSF parameters here\n",
      "  thresh: hard\n",
      "  adaptive_rms_box: True\n",
      "  adaptive_thresh: 10.\n",
      "\n",
      "image_qa_params:\n",
      "  # used when quality checks: yes/True; leave blank for defaults\n",
      "  min time on source (s):     # (default 60 s)\n",
      "  max noise (mJy/beam):       # (default 500 mJy/beam)\n",
      "  max beam axis ratio:        # (default 4)\n",
      "  max source metric:          # (default 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfgfile = '/home/erichards/work/vdp/tests/test_config.yaml'\n",
    "with open(cfgfile, 'r') as f:\n",
    "    cfg = f.read()\n",
    "    \n",
    "print cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "###################################################\n",
      "Starting the VLITE Database Pipeline.\n",
      "Log file: /home/erichards/work/data/test/201708.log\n",
      "###################################################\n",
      "Connected to database functest.\n",
      "Overwriting existing database tables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Any existing tables and data in this database will be deleted. Are you sure you want to continue? yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dropping tables if they exist...\n",
      "Creating new tables...\n",
      "_____________________________________________________________________________________\n",
      "Starting /home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "**********************\n",
      "STAGE 1: READING IMAGE\n",
      "**********************\n",
      "Performing preliminary image quality checks...\n",
      "...image passed.\n",
      "Adding new entry to image table.\n",
      "**********************\n",
      "STAGE 2: SOURCE FINDNG\n",
      "**********************\n",
      "Extracting sources...\n",
      " -- found 20 sources in 19.01 seconds\n",
      "Performing source count quality checks...\n",
      "...image passed.\n",
      "Adding detected sources to database.\n",
      "Correcting all flux measurements for primary beam response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Wrote ds9 region file '/home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.crop.pybdsm.srl.reg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "STAGE 3: SOURCE ASSOCIATION\n",
      "***************************\n",
      "Extracted 0 sources from assoc_source table within 1.5 degrees.\n",
      " -- number of matches: 0\n",
      " -- number of new sources to add: 20\n",
      "*********************************\n",
      "STAGE 4: MATCHING TO SKY CATALOGS\n",
      "*********************************\n",
      "Using the following catalogs for cross-matching: ['lofar_lba', 'nrl_nvss', 'nvss', 'sumss', 'wenss']\n",
      "Attempting to match 20 sources from this image to the lofar_lba sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 0\n",
      "Attempting to match 20 sources from this image to the nrl_nvss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 19\n",
      "Attempting to match 20 sources from this image to the nvss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 19\n",
      "Attempting to match 20 sources from this image to the sumss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 0\n",
      "Attempting to match 20 sources from this image to the wenss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 19\n",
      "===============================================================================\n",
      "Completed source finding, association, and sky catalog cross-matching on image\n",
      "/home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "===============================================================================\n",
      "--------------------------------------\n",
      "Run statistics:\n",
      "Processed 1 images.\n",
      "Total runtime: 0:00:23.215144\n"
     ]
    }
   ],
   "source": [
    "%run ../vdp.py ../tests/test_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host='localhost', database='functest', user='erichards')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check to make sure **image**, **detected_source**, **corrected_flux**, and **assoc_source** tables are being filled. The number of rows should be the same in all the source tables which should equal 'nsrc' recorded in the **image** table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('SELECT nsrc FROM image')\n",
    "nsrc = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM detected_source')\n",
    "dscnt = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM corrected_flux')\n",
    "cfcnt = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM assoc_source')\n",
    "ascnt = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "cntlist = [nsrc, dscnt, cfcnt, ascnt]\n",
    "equal_count = cntlist.count(cntlist[0]) == len(cntlist)\n",
    "if not equal_count:\n",
    "    print('FAILED: table source counts')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check various catalog matching results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correct catalogs used\n",
    "should_use = ['nrl_nvss', 'nvss', 'sumss', 'wenss', 'lofar_lba']\n",
    "cur.execute('SELECT catalogs_checked FROM image')\n",
    "did_use = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_catalogs = set(should_use) == set(did_use)\n",
    "if not correct_catalogs:\n",
    "    print('FAILED: wrong catalogs used')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sources with no catalog matches inserted into vlite_unique table\n",
    "cur.execute('SELECT id FROM assoc_source WHERE nmatches = 0')\n",
    "as_matchless_ids = cur.fetchall()\n",
    "cur.execute('SELECT assoc_id FROM vlite_unique WHERE detected')\n",
    "vu_detected_ids = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_vu_ids = set(as_matchless_ids) == set(vu_detected_ids)\n",
    "if not correct_vu_ids:\n",
    "    print('FAILED: incorrect sources in vlite_unique table')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Every catalog match recorded in 'nmatches' & catalog_match table\n",
    "cur.execute('SELECT SUM(nmatches) FROM assoc_source')\n",
    "sum_nmatches = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM catalog_match')\n",
    "cmcnt = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_nmatches = sum_nmatches == cmcnt\n",
    "if not correct_nmatches:\n",
    "    print('FAILED: number of matches different than number of sources in catalog_match table')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprocess failure triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stages, opts, setup, sfparams, qaparams, dirs = vdp.cfgparse(cfgfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overwrite': True,\n",
       " 'quality checks': True,\n",
       " 'redo match': False,\n",
       " 'reprocess': False,\n",
       " 'save to database': True,\n",
       " 'update match': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overwrite': False,\n",
       " 'quality checks': True,\n",
       " 'redo match': False,\n",
       " 'reprocess': False,\n",
       " 'save to database': True,\n",
       " 'update match': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts['overwrite'] = False\n",
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connected to database functest.\n",
      "Using existing database functest.\n"
     ]
    }
   ],
   "source": [
    "conn = vdp.dbinit(setup['database name'], setup['database user'], opts['overwrite'], qaparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________\n",
      "Starting /home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "**********************\n",
      "STAGE 1: READING IMAGE\n",
      "**********************\n",
      "Performing preliminary image quality checks...\n",
      "...image passed.\n",
      "Image already processed. Moving on...\n"
     ]
    }
   ],
   "source": [
    "# Nothing happens since image is already processed\n",
    "process(conn, stages, opts, dirs, setup['files'], setup['catalogs'], sfparams, qaparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opts['reprocess'] = True\n",
    "stages['source finding'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________\n",
      "Starting /home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "**********************\n",
      "STAGE 1: READING IMAGE\n",
      "**********************\n",
      "Performing preliminary image quality checks...\n",
      "...image passed.\n",
      "Initializing image.\n",
      "\n",
      "NOTE: /home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits's\n",
      "sources have already been associated with the existing VLITE catalog.\n",
      "*********************************\n",
      "STAGE 4: MATCHING TO SKY CATALOGS\n",
      "*********************************\n",
      "All specified catalogs with appropriate resolution have already been checked for matches.\n",
      "===============================================================================\n",
      "Completed sky catalog cross-matching for image\n",
      "/home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Nothing happens since reprocess only works when source finding is turned on\n",
    "process(conn, stages, opts, dirs, setup['files'], setup['catalogs'], sfparams, qaparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Successful reprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overwrite': False,\n",
       " 'quality checks': True,\n",
       " 'redo match': False,\n",
       " 'reprocess': True,\n",
       " 'save to database': True,\n",
       " 'update match': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stages['source finding'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________\n",
      "Starting /home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "**********************\n",
      "STAGE 1: READING IMAGE\n",
      "**********************\n",
      "Performing preliminary image quality checks...\n",
      "...image passed.\n",
      "Updating existing entries in image table.\n",
      "Removing previous sources...\n",
      "**********************\n",
      "STAGE 2: SOURCE FINDNG\n",
      "**********************\n",
      "Extracting sources...\n",
      " -- found 20 sources in 18.55 seconds\n",
      "Performing source count quality checks...\n",
      "...image passed.\n",
      "Adding detected sources to database.\n",
      "Correcting all flux measurements for primary beam response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Wrote ds9 region file '/home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.crop.pybdsm.srl.reg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "STAGE 3: SOURCE ASSOCIATION\n",
      "***************************\n",
      "Extracted 0 sources from assoc_source table within 1.5 degrees.\n",
      " -- number of matches: 0\n",
      " -- number of new sources to add: 20\n",
      "*********************************\n",
      "STAGE 4: MATCHING TO SKY CATALOGS\n",
      "*********************************\n",
      "Using the following catalogs for cross-matching: ['lofar_lba', 'nrl_nvss', 'nvss', 'sumss', 'wenss']\n",
      "Attempting to match 20 sources from this image to the lofar_lba sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 0\n",
      "Attempting to match 20 sources from this image to the nrl_nvss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 19\n",
      "Attempting to match 20 sources from this image to the nvss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 19\n",
      "Attempting to match 20 sources from this image to the sumss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 0\n",
      "Attempting to match 20 sources from this image to the wenss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 19\n",
      "===============================================================================\n",
      "Completed source finding, association, and sky catalog cross-matching on image\n",
      "/home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Reprocess the image through all stages in the same way as before\n",
    "process(conn, stages, opts, dirs, setup['files'], setup['catalogs'], sfparams, qaparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redo match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overwrite': False,\n",
       " 'quality checks': True,\n",
       " 'redo match': True,\n",
       " 'reprocess': False,\n",
       " 'save to database': True,\n",
       " 'update match': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts['reprocess'] = False\n",
    "opts['redo match'] = True\n",
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'catalog matching': True,\n",
       " 'source association': False,\n",
       " 'source finding': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages['source finding'] = False\n",
    "stages['source association'] = False\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________\n",
      "Starting /home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "**********************\n",
      "STAGE 1: READING IMAGE\n",
      "**********************\n",
      "Performing preliminary image quality checks...\n",
      "...image passed.\n",
      "Initializing image.\n",
      "Removing previous sky catalog matching results for 20 sources.\n",
      "*********************************\n",
      "STAGE 4: MATCHING TO SKY CATALOGS\n",
      "*********************************\n",
      "Using the following catalogs for cross-matching: ['lofar_lba', 'nrl_nvss', 'nvss', 'sumss', 'wenss']\n",
      "Attempting to match 20 sources from this image to the lofar_lba sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 0\n",
      "Attempting to match 20 sources from this image to the nrl_nvss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 19\n",
      "Attempting to match 20 sources from this image to the nvss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 19\n",
      "Attempting to match 20 sources from this image to the sumss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 0\n",
      "Attempting to match 20 sources from this image to the wenss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 19\n",
      "===============================================================================\n",
      "Completed sky catalog cross-matching for image\n",
      "/home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "process(conn, stages, opts, dirs, setup['files'], setup['catalogs'], sfparams, qaparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correct catalogs used\n",
    "should_use = ['nrl_nvss', 'nvss', 'sumss', 'wenss', 'lofar_lba']\n",
    "cur.execute('SELECT catalogs_checked FROM image')\n",
    "did_use = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_catalogs = set(should_use) == set(did_use)\n",
    "if not correct_catalogs:\n",
    "    print('FAILED: wrong catalogs used')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sources with no catalog matches inserted into vlite_unique table\n",
    "cur.execute('SELECT id FROM assoc_source WHERE nmatches = 0')\n",
    "as_matchless_ids = cur.fetchall()\n",
    "cur.execute('SELECT assoc_id FROM vlite_unique WHERE detected')\n",
    "vu_detected_ids = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_vu_ids = set(as_matchless_ids) == set(vu_detected_ids)\n",
    "if not correct_vu_ids:\n",
    "    print('FAILED: incorrect sources in vlite_unique table')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Every catalog match recorded in 'nmatches' & catalog_match table\n",
    "cur.execute('SELECT SUM(nmatches) FROM assoc_source')\n",
    "sum_nmatches = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM catalog_match')\n",
    "cmcnt = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_nmatches = sum_nmatches == cmcnt\n",
    "if not correct_nmatches:\n",
    "    print('FAILED: number of matches different than number of sources in catalog_match table')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove catalog matching results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "###################################################\n",
      "Starting the VLITE Database Pipeline.\n",
      "Log file: /home/erichards/work/data/test/201708.log\n",
      "###################################################\n",
      "Connected to database functest.\n",
      "Using existing database functest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For which catalogs would you like to remove matching results? (List catalogs separated by a comma.)\n",
      "nvss, nrl_nvss, wenss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing matching results for nvss, nrl_nvss, wenss...\n"
     ]
    }
   ],
   "source": [
    "# Remove NVSS, NRL_NVSS, & WENSS\n",
    "%run ../vdp.py ../tests/test_config.yaml -v 0 --remove_catalog_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host='localhost', database='functest', user='erichards')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correct catalogs used\n",
    "should_use = ['sumss', 'lofar_lba']\n",
    "cur.execute('SELECT catalogs_checked FROM image')\n",
    "did_use = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_catalogs = set(should_use) == set(did_use)\n",
    "if not correct_catalogs:\n",
    "    print('FAILED: wrong catalogs used')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sources with no catalog matches inserted into vlite_unique table\n",
    "cur.execute('SELECT id FROM assoc_source WHERE nmatches = 0')\n",
    "as_matchless_ids = cur.fetchall()\n",
    "cur.execute('SELECT assoc_id FROM vlite_unique WHERE detected')\n",
    "vu_detected_ids = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_vu_ids = set(as_matchless_ids) == set(vu_detected_ids)\n",
    "if not correct_vu_ids:\n",
    "    print('FAILED: incorrect sources in vlite_unique table')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Every catalog match recorded in 'nmatches' & catalog_match table\n",
    "cur.execute('SELECT SUM(nmatches) FROM assoc_source')\n",
    "sum_nmatches = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM catalog_match')\n",
    "cmcnt = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_nmatches = sum_nmatches == cmcnt\n",
    "if not correct_nmatches:\n",
    "    print('FAILED: number of matches different than number of sources in catalog_match table')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Update match - one catalog at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'catalog matching': True,\n",
       " 'source association': False,\n",
       " 'source finding': False}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overwrite': False,\n",
       " 'quality checks': True,\n",
       " 'redo match': False,\n",
       " 'reprocess': False,\n",
       " 'save to database': True,\n",
       " 'update match': True}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts['redo match'] = False\n",
    "opts['update match'] = True\n",
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setup['catalogs'] = ['nrl_nvss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connected to database functest.\n",
      "Using existing database functest.\n"
     ]
    }
   ],
   "source": [
    "conn = vdp.dbinit(setup['database name'], setup['database user'], opts['overwrite'], qaparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________\n",
      "Starting /home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "**********************\n",
      "STAGE 1: READING IMAGE\n",
      "**********************\n",
      "Performing preliminary image quality checks...\n",
      "...image passed.\n",
      "Initializing image.\n",
      "*********************************\n",
      "STAGE 4: MATCHING TO SKY CATALOGS\n",
      "*********************************\n",
      "Using the following catalogs for cross-matching: ['nrl_nvss']\n",
      "Attempting to match 20 sources from this image to the nrl_nvss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 19\n",
      "===============================================================================\n",
      "Completed sky catalog cross-matching for image\n",
      "/home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Add catalog matching results for NRL_NVSS\n",
    "process(conn, stages, opts, dirs, setup['files'], setup['catalogs'], sfparams, qaparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________\n",
      "Starting /home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "**********************\n",
      "STAGE 1: READING IMAGE\n",
      "**********************\n",
      "Performing preliminary image quality checks...\n",
      "...image passed.\n",
      "Initializing image.\n",
      "*********************************\n",
      "STAGE 4: MATCHING TO SKY CATALOGS\n",
      "*********************************\n",
      "Using the following catalogs for cross-matching: ['nvss']\n",
      "Attempting to match 20 sources from this image to the nvss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 19\n",
      "===============================================================================\n",
      "Completed sky catalog cross-matching for image\n",
      "/home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Add catalog matching results for NVSS\n",
    "setup['catalogs'] = ['nvss']\n",
    "process(conn, stages, opts, dirs, setup['files'], setup['catalogs'], sfparams, qaparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________\n",
      "Starting /home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "**********************\n",
      "STAGE 1: READING IMAGE\n",
      "**********************\n",
      "Performing preliminary image quality checks...\n",
      "...image passed.\n",
      "Initializing image.\n",
      "*********************************\n",
      "STAGE 4: MATCHING TO SKY CATALOGS\n",
      "*********************************\n",
      "Using the following catalogs for cross-matching: ['wenss']\n",
      "Attempting to match 20 sources from this image to the wenss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 19\n",
      "===============================================================================\n",
      "Completed sky catalog cross-matching for image\n",
      "/home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Add catalog matching results for WENSS\n",
    "setup['catalogs'] = ['wenss']\n",
    "process(conn, stages, opts, dirs, setup['files'], setup['catalogs'], sfparams, qaparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correct catalogs used\n",
    "should_use = ['sumss', 'lofar_lba', 'nrl_nvss', 'nvss', 'wenss']\n",
    "cur.execute('SELECT catalogs_checked FROM image')\n",
    "did_use = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_catalogs = set(should_use) == set(did_use)\n",
    "if not correct_catalogs:\n",
    "    print('FAILED: wrong catalogs used')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sources with no catalog matches inserted into vlite_unique table\n",
    "cur.execute('SELECT id FROM assoc_source WHERE nmatches = 0')\n",
    "as_matchless_ids = cur.fetchall()\n",
    "cur.execute('SELECT assoc_id FROM vlite_unique WHERE detected')\n",
    "vu_detected_ids = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_vu_ids = set(as_matchless_ids) == set(vu_detected_ids)\n",
    "if not correct_vu_ids:\n",
    "    print('FAILED: incorrect sources in vlite_unique table')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Every catalog match recorded in 'nmatches' & catalog_match table\n",
    "cur.execute('SELECT SUM(nmatches) FROM assoc_source')\n",
    "sum_nmatches = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM catalog_match')\n",
    "cmcnt = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_nmatches = sum_nmatches == cmcnt\n",
    "if not correct_nmatches:\n",
    "    print('FAILED: number of matches different than number of sources in catalog_match table')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update match - add all 3 at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "###################################################\n",
      "Starting the VLITE Database Pipeline.\n",
      "Log file: /home/erichards/work/data/test/201708.log\n",
      "###################################################\n",
      "Connected to database functest.\n",
      "Using existing database functest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For which catalogs would you like to remove matching results? (List catalogs separated by a comma.)\n",
      "nvss, nrl_nvss, wenss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing matching results for nvss, nrl_nvss, wenss...\n"
     ]
    }
   ],
   "source": [
    "# Remove them again\n",
    "%run ../vdp.py ../tests/test_config.yaml -v 0 --remove_catalog_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stages, opts, setup, sfparams, qaparams, dirs = vdp.cfgparse(cfgfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'catalog matching': True,\n",
       " 'source association': False,\n",
       " 'source finding': False}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages['source finding'] = False\n",
    "stages['source association'] = False\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overwrite': False,\n",
       " 'quality checks': True,\n",
       " 'redo match': False,\n",
       " 'reprocess': False,\n",
       " 'save to database': True,\n",
       " 'update match': True}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts['overwrite'] = False\n",
    "opts['update match'] = True\n",
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cosmos',\n",
       " 'first',\n",
       " 'gleam',\n",
       " 'gpsr1',\n",
       " 'gpsr5',\n",
       " 'lazio04',\n",
       " 'lofar_hba',\n",
       " 'lofar_lba',\n",
       " 'lotss',\n",
       " 'm31_glg04',\n",
       " 'nordgc',\n",
       " 'nrl_nvss',\n",
       " 'nvss',\n",
       " 'sevenc',\n",
       " 'sumss',\n",
       " 'tgss',\n",
       " 'txs',\n",
       " 'vlssr',\n",
       " 'wenss']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup['catalogs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________\n",
      "Starting /home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "**********************\n",
      "STAGE 1: READING IMAGE\n",
      "**********************\n",
      "Performing preliminary image quality checks...\n",
      "...image passed.\n",
      "Initializing image.\n",
      "*********************************\n",
      "STAGE 4: MATCHING TO SKY CATALOGS\n",
      "*********************************\n",
      "Using the following catalogs for cross-matching: ['nrl_nvss', 'nvss', 'wenss']\n",
      "Attempting to match 20 sources from this image to the nrl_nvss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 19\n",
      "Attempting to match 20 sources from this image to the nvss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 19\n",
      "Attempting to match 20 sources from this image to the wenss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 19\n",
      "===============================================================================\n",
      "Completed sky catalog cross-matching for image\n",
      "/home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Now add them all back\n",
    "process(conn, stages, opts, dirs, setup['files'], setup['catalogs'], sfparams, qaparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correct catalogs used\n",
    "should_use = ['sumss', 'lofar_lba', 'nrl_nvss', 'nvss', 'wenss']\n",
    "cur.execute('SELECT catalogs_checked FROM image')\n",
    "did_use = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_catalogs = set(should_use) == set(did_use)\n",
    "if not correct_catalogs:\n",
    "    print('FAILED: wrong catalogs used')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sources with no catalog matches inserted into vlite_unique table\n",
    "cur.execute('SELECT id FROM assoc_source WHERE nmatches = 0')\n",
    "as_matchless_ids = cur.fetchall()\n",
    "cur.execute('SELECT assoc_id FROM vlite_unique WHERE detected')\n",
    "vu_detected_ids = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_vu_ids = set(as_matchless_ids) == set(vu_detected_ids)\n",
    "if not correct_vu_ids:\n",
    "    print('FAILED: incorrect sources in vlite_unique table')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Every catalog match recorded in 'nmatches' & catalog_match table\n",
    "cur.execute('SELECT SUM(nmatches) FROM assoc_source')\n",
    "sum_nmatches = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM catalog_match')\n",
    "cmcnt = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_nmatches = sum_nmatches == cmcnt\n",
    "if not correct_nmatches:\n",
    "    print('FAILED: number of matches different than number of sources in catalog_match table')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add another image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# vdp configuration file\n",
      "\n",
      "stages:\n",
      "                              # processing steps; yes | no  or  True | False\n",
      "  source finding: yes         # extract sources from image?\n",
      "  source association: yes     # match extracted sources to existing catalog?\n",
      "  catalog matching: yes       # cross-match with sky survey catalogs?\n",
      "\n",
      "options:\n",
      "                              # processing options; yes | no or True | False\n",
      "  save to database: yes       # save results to database?\n",
      "  quality checks: yes         # run image & source count quality checks?\n",
      "  overwrite: no               # overwrite database if exists?\n",
      "  reprocess: no               # redo selected stages even if done previously?\n",
      "  redo match: no              # redo cross-matching with all sky catalogs?\n",
      "  update match: no            # update cross-matching with new sky catalogs?\n",
      "\n",
      "setup:\n",
      "  root directory: /home/erichards/work/data/test/\n",
      "  year: 2017\n",
      "  month: 08\n",
      "  day: [30]                   # list of days to process; [] = all\n",
      "  # list files to process - put different days in separate lists; [[]] = all\n",
      "  files: [[1.5GHz.0137+331.IPln1.fits, 6GHz.0137+331.IPln1.fits]]\n",
      "  database name: functest\n",
      "  database user: erichards\n",
      "  catalogs: []                # [] = all\n",
      "\n",
      "pybdsf_params:\n",
      "  mode: default               # default | minimize_islands\n",
      "  scale: 0.5                  # fraction (0-1) of image size (radius) to use\n",
      "  # Specify all PyBDSF parameters here\n",
      "  thresh: hard\n",
      "  adaptive_rms_box: True\n",
      "  adaptive_thresh: 10.\n",
      "\n",
      "image_qa_params:\n",
      "  # used when quality checks: yes/True; leave blank for defaults\n",
      "  min time on source (s):     # (default 60 s)\n",
      "  max noise (mJy/beam):       # (default 500 mJy/beam)\n",
      "  max beam axis ratio:        # (default 4)\n",
      "  max source metric:          # (default 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(cfgfile, 'r') as f:\n",
    "    cfg = f.read()\n",
    "    \n",
    "print cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "###################################################\n",
      "Starting the VLITE Database Pipeline.\n",
      "Log file: /home/erichards/work/data/test/201708.log\n",
      "###################################################\n",
      "Connected to database functest.\n",
      "Using existing database functest.\n",
      "_____________________________________________________________________________________\n",
      "Starting /home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits.\n",
      "**********************\n",
      "STAGE 1: READING IMAGE\n",
      "**********************\n",
      "Performing preliminary image quality checks...\n",
      "...image passed.\n",
      "Image already processed. Moving on...\n",
      "___________________________________________________________________________________\n",
      "Starting /home/erichards/work/data/test/2017-08/30/Images/6GHz.0137+331.IPln1.fits.\n",
      "**********************\n",
      "STAGE 1: READING IMAGE\n",
      "**********************\n",
      "Performing preliminary image quality checks...\n",
      "...image passed.\n",
      "Adding new entry to image table.\n",
      "**********************\n",
      "STAGE 2: SOURCE FINDNG\n",
      "**********************\n",
      "Extracting sources...\n",
      " -- found 45 sources in 20.19 seconds\n",
      "Performing source count quality checks...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Wrote ds9 region file '/home/erichards/work/data/test/2017-08/30/Images/6GHz.0137+331.IPln1.crop.pybdsm.srl.reg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...image passed.\n",
      "Adding detected sources to database.\n",
      "Correcting all flux measurements for primary beam response.\n",
      "***************************\n",
      "STAGE 3: SOURCE ASSOCIATION\n",
      "***************************\n",
      "Extracted 20 sources from assoc_source table within 1.5 degrees.\n",
      "Limiting to sources in resolution class C (35.0\" < BMIN <= 60.0\")\n",
      " -- 20 sources remaining\n",
      "Attempting to match 45 sources from this image to 20 sources previously detected in VLITE images...\n",
      " -- number of matches: 19\n",
      " -- number of new sources to add: 26\n",
      "*********************************\n",
      "STAGE 4: MATCHING TO SKY CATALOGS\n",
      "*********************************\n",
      "Using the following catalogs for cross-matching: ['lofar_lba', 'nrl_nvss', 'nvss', 'sumss', 'wenss']\n",
      "Attempting to match 26 sources from this image to the lofar_lba sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 0\n",
      "Attempting to match 26 sources from this image to the nrl_nvss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 23\n",
      "Attempting to match 26 sources from this image to the nvss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 23\n",
      "Attempting to match 26 sources from this image to the sumss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 0\n",
      "Attempting to match 26 sources from this image to the wenss sky catalog...\n",
      " -- found previous matching results for 0 sources\n",
      " -- number of matches: 23\n",
      "===============================================================================\n",
      "Completed source finding, association, and sky catalog cross-matching on image\n",
      "/home/erichards/work/data/test/2017-08/30/Images/6GHz.0137+331.IPln1.fits.\n",
      "===============================================================================\n",
      "--------------------------------------\n",
      "Run statistics:\n",
      "Processed 11 images.\n",
      "Total runtime: 0:00:21.707448\n"
     ]
    }
   ],
   "source": [
    "%run ../vdp.py ../tests/test_config.yaml -v 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host='localhost', database='functest', user='erichards')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure new sources are being added and the number of detections is being incrememted correctly in the **assoc_source** table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur.execute('SELECT nsrc FROM image ORDER BY id')\n",
    "nsrcs = cur.fetchall()\n",
    "im1nsrc, im2nsrc = nsrcs[0][0], nsrcs[1][0]\n",
    "cur.execute('SELECT COUNT(1) FROM assoc_source')\n",
    "ascnt = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM assoc_source WHERE ndetect > 1')\n",
    "multi_detect_cnt = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "im1_only = (ascnt - im2nsrc) == (im1nsrc - multi_detect_cnt)\n",
    "if not im1_only:\n",
    "    print('FAILED: assoc_source table incorrect after adding new image')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check various catalog matching results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sources with no catalog matches inserted into vlite_unique table\n",
    "cur.execute('SELECT id FROM assoc_source WHERE nmatches = 0')\n",
    "as_matchless_ids = cur.fetchall()\n",
    "cur.execute('SELECT assoc_id FROM vlite_unique WHERE detected')\n",
    "vu_detected_ids = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_vu_ids = set(as_matchless_ids) == set(vu_detected_ids)\n",
    "if not correct_vu_ids:\n",
    "    print('FAILED: incorrect sources in vlite_unique table')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Every catalog match recorded in 'nmatches' & catalog_match table\n",
    "cur.execute('SELECT SUM(nmatches) FROM assoc_source')\n",
    "sum_nmatches = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM catalog_match')\n",
    "cmcnt = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "correct_nmatches = sum_nmatches == cmcnt\n",
    "if not correct_nmatches:\n",
    "    print('FAILED: number of matches different than number of sources in catalog_match table')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Every VU source detected in one image should have recorded non-detections in the other if there are no\n",
    "# multi-detection VU sources (ndetect > 1, nmatches = 0)\n",
    "cur.execute('SELECT COUNT(1) FROM assoc_source WHERE nmatches = 0 AND ndetect > 1')\n",
    "multi_detect_VU = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM vlite_unique WHERE image_id = 1 AND detected')\n",
    "im1VU_detect = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM vlite_unique WHERE image_id = 2 AND NOT detected')\n",
    "im2VU_nodetect = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM vlite_unique WHERE image_id = 2 AND detected')\n",
    "im2VU_detect = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM vlite_unique WHERE image_id = 1 AND NOT detected')\n",
    "im1VU_nodetect = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "same1 = (im1VU_detect - multi_detect_VU) == im2VU_nodetect\n",
    "same2 = (im2VU_detect - multi_detect_VU) == im1VU_nodetect\n",
    "if not same1 or not same2:\n",
    "    print('FAILED: vlite_unique table incorrect')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "###################################################\n",
      "Starting the VLITE Database Pipeline.\n",
      "Log file: /home/erichards/work/data/test/201708.log\n",
      "###################################################\n",
      "Connected to database functest.\n",
      "Using existing database functest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please enter the image(s) filename(s) starting at least with the year-month directory (i.e. 2018-01/15/Images/10GHz.Mrk110.IPln1.fits), or provide a text file with one filename per line:\n",
      "/home/erichards/work/data/test/2017-08/30/Images/1.5GHz.0137+331.IPln1.fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing to remove image(s) ['2017-08/30/Images/1.5GHz.0137+331.IPln1.fits'] from the database.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Are you sure? yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting image(s) from the database...\n"
     ]
    }
   ],
   "source": [
    "%run ../vdp.py ../tests/test_config.yaml -v 0 --remove_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host='localhost', database='functest', user='erichards')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Make sure the image was deleted from the image table\n",
    "cur.execute('SELECT COUNT(1) FROM image WHERE id = 1')\n",
    "if not cur.fetchone()[0] == 0:\n",
    "    print('FAILED: image still in image table')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure sources where removed from detected_source, detected_island, & corrected_flux tables\n",
    "cur.execute('SELECT COUNT(1) FROM detected_island WHERE image_id = 1')\n",
    "dicnt = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM detected_source WHERE image_id = 1')\n",
    "dscnt = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM corrected_flux WHERE image_id = 1')\n",
    "cfcnt = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "if not dicnt == 0 or not dscnt == 0 or not cfcnt == 0:\n",
    "    print('FAILED: sources still in tables')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make sure the only sources in assoc_source are in image 2\n",
    "cur.execute('SELECT assoc_id FROM detected_source')\n",
    "ds_assoc_ids = cur.fetchall()\n",
    "cur.execute('SELECT id FROM assoc_source')\n",
    "as_ids = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "same_ids = set(ds_assoc_ids) == set(as_ids)\n",
    "if not same_ids:\n",
    "    print('FAILED: incorrect sources in assoc_source')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Make sure 'ndetect' was decremented\n",
    "cur.execute('SELECT COUNT(1) FROM assoc_source WHERE ndetect > 1')\n",
    "if not cur.fetchone()[0] == 0:\n",
    "    print('FAILED: wrong ndetect in assoc_source table')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Make sure sources were removed from vlite_unique\n",
    "cur.execute('SELECT COUNT(1) FROM vlite_unique WHERE image_id = 1')\n",
    "if not cur.fetchone()[0] == 0:\n",
    "    print('FAILED: sources still in vlite_unique table')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure entries were removed from catalog_match\n",
    "cur.execute('SELECT SUM(nmatches) FROM assoc_source')\n",
    "asnmatches = cur.fetchone()[0]\n",
    "cur.execute('SELECT COUNT(1) FROM catalog_match')\n",
    "cmcnt = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "if not asnmatches == cmcnt:\n",
    "    print('FAILED: sources still in catalog_match')\n",
    "else:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
